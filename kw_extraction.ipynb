{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sketch Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Parse the json response\n",
    "reviews = []\n",
    "ratings = []\n",
    "\n",
    "with open('./json/butcher-reviews.json') as f:\n",
    "    reviews_temp = json.load(f)\n",
    "    for review in reviews_temp:\n",
    "        reviews.append(review['snippet'])\n",
    "        ratings.append(review['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176\n",
      "176\n",
      "I don’t know where to begin. The staff is extremely friendly and professional. Very knowledgeable and helpful. We are not very accustomed to this kind of restaurant, and they helped us pick items and the right wine. Steaks were perfectly cooked. Sides were phenomenal. The cheesecake is to die for. Highly recommend for a special night out.\n",
      "\n",
      "Trendy and chic, incredibly decadent and lavish. Great place to celebrate a special occasion. Of course amazing steaks as you’d expect. The ceviche was amazing, and the cheesecake dessert was a work of art! Amazing cocktail options and incredible variety of bourbon. Lots of rare options that you can’t find elsewhere.\n",
      "\n",
      "Fantastic Steak and Seafood Restaurant. Service was impeccable, food was outstanding. Drinks and wine were top notch. One of the best restaurants in Toronto. It's a hidden gem in the city. Minutes away from Scotiabank Arena at Bay and Harbour Streets. Great for business meetings, date nights or out with friends. They have an outdoor patio too and a private diningroom. Make reservations ahead of time.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))\n",
    "print(len(ratings))\n",
    "for i, review in enumerate(reviews):\n",
    "    if i > 2: break\n",
    "    print(review + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from turtle import distance\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "n_gram_range = (1, 1) # [lower bound, upper bound]\n",
    "stop_words = \"english\"\n",
    "\n",
    "# Extract candidate words/phrases\n",
    "count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit(reviews)\n",
    "candidates = count.get_feature_names_out()\n",
    "custom_kws = ['quite', 'intimate', 'dim', 'waygu'] # cutom kws can be passed from FE in the future\n",
    "\n",
    "# Next, we convert both the reviews as well as the candidate keywords/keyphrases to numerical data using pre-trained BERT\n",
    "model = SentenceTransformer('distilbert-base-nli-mean-tokens')\n",
    "review_embeddings = model.encode(reviews)\n",
    "candidate_embeddings = model.encode(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords extracted:\n",
      " ['chef', 'appetizers', 'dinner', 'deliciousness', 'culinary', 'chefs', 'dinners', 'flavoursome', 'flavorful', 'tasty']\n"
     ]
    }
   ],
   "source": [
    "# Use cosine similarity to compare candidate embeddings with all review embeddings (vectorized)\n",
    "top_n = 10\n",
    "distances = cosine_similarity(candidate_embeddings, review_embeddings) # return kernel matrix ndarray of shape (n_samples_X, n_samples_Y)\n",
    "\n",
    "# Compute the mean similarity for each candidate kw (vectorized)\n",
    "mean_distances = np.mean(distances, axis=1)\n",
    "# print(f'mean_distances shape: {mean_distances.shape}')\n",
    "\n",
    "keywords = [candidates[index] for index in mean_distances.argsort()[-top_n:]]\n",
    "print(f'top {top_n} keywords extracted:\\n {keywords}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top 10 keywords extracted:\n",
      " ['tasty', 'steakhouses', 'waiter', 'foodie', 'sauvignon', 'dinners', 'rich', 'chefs', 'flavoursome', 'appetizers']\n"
     ]
    }
   ],
   "source": [
    "# Diversification of returned KWs result\n",
    "def mmr(doc_embeddingss, word_embeddings, words, top_n, diversity):\n",
    "    '''Higher diversity (0 - 1) = more diverse'''\n",
    "\n",
    "    # Extract similarity within words, and between words and the reviews\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embeddingss)\n",
    "    word_doc_similarity_mean = np.mean(word_doc_similarity, axis=1).reshape(-1, 1)\n",
    "    word_similarity = cosine_similarity(word_embeddings)\n",
    "\n",
    "    # Initialize candidates and already chosen best keyword/keyphras\n",
    "    keywords_idx = [np.argmax(word_doc_similarity_mean)]\n",
    "    candidates_idx = [i for i in range(len(words)) if i != keywords_idx[0]]\n",
    "\n",
    "    for _ in range(top_n - 1):\n",
    "        # Extract similarities within candidates and\n",
    "        # between candidates and selected keywords/phrases\n",
    "        candidate_similarities = word_doc_similarity_mean[candidates_idx, :]\n",
    "        target_similarities = np.max(word_similarity[candidates_idx][:, keywords_idx], axis=1)\n",
    "\n",
    "        # Calculate MMR\n",
    "        mmr = (1-diversity) * candidate_similarities - diversity * target_similarities.reshape(-1, 1)\n",
    "        mmr_idx = candidates_idx[np.argmax(mmr)]\n",
    "\n",
    "        # Update keywords & candidates\n",
    "        keywords_idx.append(mmr_idx)\n",
    "        candidates_idx.remove(mmr_idx)\n",
    "\n",
    "    return [words[idx] for idx in keywords_idx]\n",
    "\n",
    "kws= mmr(doc_embeddingss=review_embeddings, word_embeddings=candidate_embeddings, words=candidates, top_n=10, diversity=0.2)\n",
    "print(f'top {top_n} keywords extracted:\\n {kws}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tasty': 4,\n",
       " 'steakhouses': 3,\n",
       " 'waiter': 7,\n",
       " 'foodie': 2,\n",
       " 'sauvignon': 1,\n",
       " 'dinners': 1,\n",
       " 'rich': 2,\n",
       " 'chefs': 3,\n",
       " 'flavoursome': 1,\n",
       " 'appetizers': 4,\n",
       " 'quite': 4,\n",
       " 'intimate': 7,\n",
       " 'dim': 0,\n",
       " 'waygu': 2}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adding custom keywords from FE user input to the final extracted KWs list\n",
    "for kw in custom_kws:\n",
    "    if kw not in kws:\n",
    "        kws.append(kw)\n",
    "\n",
    "# Iteractive through concated reviews to get keywords count and store in a dict\n",
    "concat_reviews = ' '.join(reviews).lower()\n",
    "kws_cnt = {}\n",
    "for kw in kws:\n",
    "    # count() returns the number of occurrences of a substring in a give string\n",
    "    cnt = concat_reviews.count(kw)\n",
    "    kws_cnt[kw] = cnt\n",
    "\n",
    "kws_cnt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pleasure',\n",
       " 'flavour',\n",
       " 'complimentary',\n",
       " 'tasted',\n",
       " 'concise',\n",
       " 'tastes',\n",
       " 'ambience',\n",
       " 'impeccable',\n",
       " 'timely',\n",
       " 'seasoned']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_similar_kw(kw, doc_embeddings, word_embeddings, words, top_n=100) -> list:\n",
    "    '''\n",
    "    Take a string keywords as input and find the closest meaning kw in the top top_N keyword candidates\n",
    "    '''\n",
    "\n",
    "    # Extract similarity within words, and between words and the reviews\n",
    "    word_doc_similarity = cosine_similarity(word_embeddings, doc_embeddings)\n",
    "    word_doc_similarity_mean = np.mean(word_doc_similarity, axis=1)\n",
    "\n",
    "    # Get top_n keywords representive to doc embeddings\n",
    "    keywords = [words[index] for index in word_doc_similarity_mean.argsort()[-top_n:]]\n",
    "\n",
    "    # Compute input kw embedding and compute its similarity with extracted top_n keywords\n",
    "    kw_emb = model.encode([kw])\n",
    "    kw_similarity = cosine_similarity(model.encode(keywords), kw_emb).reshape(-1,)\n",
    "\n",
    "    # Take the most similar keywords\n",
    "    similar_kw = [keywords[index] for index in kw_similarity.argsort()[-10:]]\n",
    "    \n",
    "    return similar_kw\n",
    "\n",
    "find_similar_kw(kw='dim', doc_embeddings=review_embeddings, word_embeddings=candidate_embeddings, words=candidates, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('date-place-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "195e95527db56725f0ea9ab9e93d5f299c7dde777c2bd2ccf2f79ad134f4a22b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
